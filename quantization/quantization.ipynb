{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "550a86be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3f0e108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_tensor_symmetric(x: torch.tensor, n_bits: int):\n",
    "    q_max = 2 ** (n_bits - 1) - 1\n",
    "    q_min = - q_max\n",
    "\n",
    "    max_val = x.abs().max()\n",
    "\n",
    "    scale = max_val / q_max\n",
    "    if scale == 0.0:\n",
    "        scale = 1.0\n",
    "\n",
    "    quantized = torch.clamp(\n",
    "        torch.round(x / scale), \n",
    "        q_min, q_max\n",
    "    ).to(torch.int8)\n",
    "\n",
    "    return quantized, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0f62c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dequantize_tensor_assymetric(quantized: torch.tensor, scale: float):\n",
    "    return quantized.float() * scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8911fc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_tensor_asymmetric(x: torch.tensor, n_bits: int):\n",
    "    q_max = 2 ** (n_bits - 1) - 1\n",
    "    q_min = - q_max\n",
    "\n",
    "    max_val = x.max()\n",
    "    min_val = x.min()\n",
    "\n",
    "    scale = (max_val - min_val) / (q_max - q_min)\n",
    "    if scale == 0.0:\n",
    "        scale = 1.0\n",
    "\n",
    "    zero_point = q_min - torch.round(min_val / scale)\n",
    "    zero_point = torch.clamp(zero_point, q_min, q_max).to(torch.int8)\n",
    "\n",
    "    quantized = torch.clamp(\n",
    "        torch.round(x / scale) + zero_point, \n",
    "        q_min, q_max\n",
    "    ).to(torch.int8)\n",
    "\n",
    "    return quantized, scale, zero_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbbe3c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dequantize_tensor_asymmetric(quantized: torch.tensor, scale: float, zero_point: int):\n",
    "    return (quantized - zero_point).float() * scale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc38eb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_channel_quantization_symmetric(x: torch.tensor, channel_dim: int, n_bits: int):\n",
    "    q_max = 2 ** (n_bits - 1) - 1\n",
    "    q_min = - q_max\n",
    "\n",
    "    transposed_x = x.transpose(0, channel_dim) if channel_dim != 0 else x\n",
    "    quantized_channels = []\n",
    "    scales = []\n",
    "\n",
    "    for i in range(transposed_x.shape[0]):\n",
    "        channel_data = transposed_x[i,:]\n",
    "        max_val = channel_data.abs().max()\n",
    "\n",
    "        scale = max_val / q_max\n",
    "        if scale == 0.0:\n",
    "            scale = 1.0\n",
    "\n",
    "        quantized_channel = torch.clamp(\n",
    "            torch.round(channel_data / scale), \n",
    "            q_min, q_max\n",
    "        ).to(torch.int8)\n",
    "\n",
    "        quantized_channels.append(quantized_channel)\n",
    "        scales.append(scale)\n",
    "\n",
    "    quantized = torch.stack(quantized_channels, dim=0)\n",
    "    scales = torch.tensor(scales)\n",
    "\n",
    "    quantized = quantized.transpose(0, channel_dim) if channel_dim != 0 else quantized\n",
    "\n",
    "    return quantized, scales\n",
    "\n",
    "def per_channel_dequantization_symmetric(quantized: torch.tensor, scales: torch.tensor, channel_dim: int):\n",
    "    quantized = quantized.transpose(0, channel_dim) if channel_dim != 0 else quantized\n",
    "    dequantized = []\n",
    "\n",
    "    for i in range(quantized.shape[0]):\n",
    "        channel_data = quantized[i]\n",
    "        scale = scales[i]\n",
    "\n",
    "        dq = channel_data.float() * scale\n",
    "        dequantized.append(dq)\n",
    "\n",
    "    dequantized = dequantized.transpose(0, channel_dim) if channel_dim != 0 else dequantized\n",
    "\n",
    "    return torch.stack(dequantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86897153",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantizedLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, channel_dim, n_bits=8):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fp32_weight = nn.Linear(in_features, out_features)\n",
    "        self.n_bits = n_bits\n",
    "        self.channel_dim = channel_dim\n",
    "\n",
    "        self.register_buffer('weight_quantized', torch.zeros(out_features, in_features, dtype=torch.int8))\n",
    "        self.register_buffer('weight_scale', torch.ones(out_features))\n",
    "\n",
    "        self.register_buffer('activation_scale', torch.ones(out_features))\n",
    "\n",
    "        self.quantized = False\n",
    "\n",
    "    def quantize_weights(self):\n",
    "        if self.quantized:\n",
    "            return \n",
    "\n",
    "        weight = self.fp32_weight.weight.data\n",
    "        quantized, scales = per_channel_quantization_symmetric(weight, self.channel_dim, self.n_bits)\n",
    "\n",
    "        self.weight_quantized = quantized\n",
    "        self.weight_scale = scales  \n",
    "\n",
    "        self.quantized = True\n",
    "\n",
    "    def set_activation_scale(self, scale):\n",
    "        self.activation_scale = scale\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.quantized:\n",
    "            return nn.functional.linear(x, self.fp32_weight)\n",
    "        \n",
    "        x_q, x_scale = per_channel_quantization_symmetric(x, self.channel_dim, self.n_bits)\n",
    "\n",
    "        w_dq = per_channel_dequantization_symmetric(self.weight_quantized, self.weight_scale, self.channel_dim)\n",
    "        x_dq = per_channel_dequantization_symmetric(x_q, x_scale, self.channel_dim)\n",
    "\n",
    "        return nn.functional.linear(x_dq, w_dq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c817b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantizedModel(nn.Module):\n",
    "    \"\"\"Quantized version\"\"\"\n",
    "    def __init__(self, input_size=784, hidden_size=256, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.fc1 = QuantizedLinear(input_size, hidden_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = QuantizedLinear(hidden_size, hidden_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = QuantizedLinear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu1(self.fc1(x))\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def quantize_all_weights(self):\n",
    "        \"\"\"Quantize all linear layers\"\"\"\n",
    "        self.fc1.quantize_weights()\n",
    "        self.fc2.quantize_weights()\n",
    "        self.fc3.quantize_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e808220e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2466277",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeQuantization(Function):\n",
    "    @staticmethod\n",
    "    def forward(self, x, scale, zero_point, q_max, q_min):\n",
    "        quantized = torch.clamp(\n",
    "            torch.round(x / scale) + zero_point, \n",
    "            q_min, q_max\n",
    "        ).to(torch.int8)\n",
    "\n",
    "        dequantizd = (quantized - zero_point).float() * scale\n",
    "        return dequantizd\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(self, grad_output):\n",
    "        return grad_output, None, None, None, None\n",
    "\n",
    "fake_quantization = FakeQuantization.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f8dfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxObserver(nn.Module):\n",
    "    def __init__(self, n_bits=8):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_bits = n_bits\n",
    "\n",
    "        self.quantized_max = 2 ** (n_bits - 1) - 1\n",
    "        self.quantized_min = - self.quantized_max\n",
    "\n",
    "        self.register_buffer('max_val', torch.tensor(float('-inf')))\n",
    "        self.register_buffer('min_val', torch.tensor(float('inf')))\n",
    "\n",
    "        self.register_buffer('scale', torch.tensor(1.0))\n",
    "        self.register_buffer('zero_point', torch.tensor(0.0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            max_val = x.max()\n",
    "            min_val = x.min()\n",
    "\n",
    "            self.max_val = torch.max(max_val, self.max_val)\n",
    "            self.min_val = torch.min(min_val, self.min_val)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def calculate_params(self):\n",
    "        self.scale = (self.max_val - self.min_val) / (self.quantized_max - self.quantized_min)\n",
    "        if self.scale == 0.0:\n",
    "            self.scale = 1.0\n",
    "        \n",
    "        zero_point = self.quantized_min - torch.round(self.min_val / self.scale)\n",
    "        zero_point = torch.clamp(zero_point, self.quantized_min, self.quantized_max)\n",
    "\n",
    "        self.zero_point = zero_point\n",
    "\n",
    "        return self.scale, self.zero_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388fab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovingAverageMinMaxObserver(MinMaxObserver):\n",
    "    def __init__(self, averaging_constant, n_bits=8):\n",
    "        super().__init__(n_bits)\n",
    "        self.averaging_constant = averaging_constant\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            min_val = x.min_val()\n",
    "            max_val = x.max_val()\n",
    "\n",
    "            if self.min_val == float('inf'):\n",
    "                self.min_val = min_val\n",
    "                self.max_val = max_val\n",
    "            else:\n",
    "                self.min_val = self.averaging_constant * self.min_val + (1. - self.averaging_constant) * min_val\n",
    "                self.max_val = self.averaging_constant * self.max_val + (1. - self.averaging_constant) * max_val\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25ed9761",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QATLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "\n",
    "        self.weight_observer = MovingAverageMinMaxObserver(0.9)\n",
    "        self.activation_observer = MovingAverageMinMaxObserver(0.9)\n",
    "\n",
    "        self.register_buffer('weight_scale', torch.tensor(1.0))\n",
    "        self.register_buffer('weight_zero_point', torch.tensor(0.0))\n",
    "        self.register_buffer('activation_scale', torch.tensor(1.0))\n",
    "        self.register_buffer('activation_zero_point', torch.tensor(0.0))\n",
    "\n",
    "        self.qat_mode = False\n",
    "\n",
    "    def enable_observers(self):\n",
    "        for module in self.modules:\n",
    "            if isinstance(module, (MinMaxObserver, MovingAverageMinMaxObserver)):\n",
    "                module.train()\n",
    "\n",
    "    def disable_observer(self):\n",
    "        for module in self.modules:\n",
    "            if isinstance(module, (MinMaxObserver, MovingAverageMinMaxObserver)):\n",
    "                module.eval()\n",
    "\n",
    "    def calculate_params(self):\n",
    "        with torch.no_grad():\n",
    "            self.weight_observer(self.linear)\n",
    "            self.weight_scale, self.weight_zero_point = self.weight_observer.calculate_params()\n",
    "\n",
    "            self.activation_scale, self.activation_zero_point = self.activation_observer.calculate_params()\n",
    "\n",
    "    def enable_qat(self):\n",
    "        self.qat_mode = True\n",
    "        self.calculate_params()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation_observer(x)\n",
    "\n",
    "        if not self.qat_mode:\n",
    "            return nn.functional.linear(x, self.linear)\n",
    "        \n",
    "        x_fq = fake_quantization(\n",
    "            x, \n",
    "            self.activation_scale, \n",
    "            self.activation_zero_point,\n",
    "            self.activation_observer.quantized_max, \n",
    "            self.activation_observer.quantized_min\n",
    "        )\n",
    "\n",
    "        weight_fq = fake_quantization(\n",
    "            self.linear, \n",
    "            self.weight_scale, \n",
    "            self.weight_zero_point,\n",
    "            self.weight_observer.quantized_max,\n",
    "            self.weight_observer.quantized_min\n",
    "        )\n",
    "\n",
    "        return nn.functional.linear(x_fq, weight_fq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "552c334a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QATModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Complete model with QAT support\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=784, hidden_size=256, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.fc1 = QATLinear(input_size, hidden_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = QATLinear(hidden_size, hidden_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = QATLinear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu1(self.fc1(x))\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def enable_observer(self):\n",
    "        \"\"\"Enable all observers for calibration\"\"\"\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, QATLinear):\n",
    "                module.enable_observer()\n",
    "    \n",
    "    def disable_observer(self):\n",
    "        \"\"\"Disable all observers after calibration\"\"\"\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, QATLinear):\n",
    "                module.disable_observer()\n",
    "    \n",
    "    def calculate_qparams(self):\n",
    "        \"\"\"Calculate quantization parameters for all layers\"\"\"\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, QATLinear):\n",
    "                module.calculate_qparams()\n",
    "    \n",
    "    def enable_qat(self):\n",
    "        \"\"\"Enable QAT mode (fake quantization)\"\"\"\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, QATLinear):\n",
    "                module.enable_qat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24649c9",
   "metadata": {},
   "source": [
    "## GPTQ Pending"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
