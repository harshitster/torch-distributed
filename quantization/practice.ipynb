{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fefa64fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696cd02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_tensor_symmetric(tensor: torch.tensor, n_bits=8):\n",
    "    q_max = 2 ** (n_bits - 1) - 1\n",
    "    q_min = - q_max\n",
    "\n",
    "    max_val = tensor.abs().max()\n",
    "    min_val = tensor.abs().min()\n",
    "\n",
    "    scale = (max_val - min_val) / (q_max - q_min)\n",
    "\n",
    "    if scale == 0.0:\n",
    "        scale = 1.0\n",
    "\n",
    "    quantized = torch.clamp(\n",
    "        tensor / scale, q_min, q_max\n",
    "    ).to(torch.int8)\n",
    "\n",
    "    return quantized, scale\n",
    "\n",
    "def dequantize_tensor_symmetric(quantized: torch.tensor, scale: float):\n",
    "    return quantized.float() * scale\n",
    "\n",
    "def quantize_tensor_asymmetric(tensor: torch.tensor, n_bits=8):\n",
    "    q_max = 2 ** (n_bits - 1) - 1\n",
    "    q_min = - q_max\n",
    "\n",
    "    max_val = tensor.max()\n",
    "    min_val = tensor.abs().min()\n",
    "\n",
    "    scale = (max_val - min_val) / (q_max - q_min)\n",
    "\n",
    "    if scale == 0.0:\n",
    "        scale = 1.0\n",
    "\n",
    "    zero_point = q_min - torch.round(min_val / scale)\n",
    "    zero_point = torch.clamp(zero_point, min_val, max_val).to(torch.int8)\n",
    "\n",
    "    quantized = torch.clamp(\n",
    "        tensor / scale + zero_point, \n",
    "        q_min, q_max\n",
    "    ).to(torch.int8)\n",
    "\n",
    "    return quantized, scale, zero_point\n",
    "\n",
    "def dequantize_tensor_asymmetric(quantized: torch.tensor, scale: float, zero_point: int):\n",
    "    return (quantized - zero_point).float() * scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f661d4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_channel_quantization(tensor: torch.tensor, channel_dim: int, n_bits: int = 8):\n",
    "    q_max = 2 ** (n_bits - 1) - 1\n",
    "    q_min = - q_max\n",
    "\n",
    "    tranposed_tensor = tensor.transpose(0, channel_dim) if channel_dim != 0 else tensor\n",
    "\n",
    "    quantized_list = []\n",
    "    scales = []\n",
    "    zero_points = []\n",
    "\n",
    "    for c in range(tranposed_tensor.shape[0]):\n",
    "        channel_data = tranposed_tensor[c,:]\n",
    "        max_val = channel_data.max()\n",
    "        min_val = channel_data.min()\n",
    "\n",
    "        scale = (max_val - min_val) / (q_max - q_min)\n",
    "\n",
    "        if scale == 0.0:\n",
    "            scale = 1.0\n",
    "\n",
    "        zero_point = q_min - torch.round(min_val / scale)\n",
    "        zero_point = torch.clamp(zero_point, q_min, q_max).to(torch.int8)\n",
    "\n",
    "        quantized_channel_data = torch.clamp(\n",
    "            channel_data / scale + zero_point, q_min, q_max\n",
    "        ).to(torch.int8)\n",
    "\n",
    "        quantized_list.append(quantized_channel_data)\n",
    "        scales.append(scale)\n",
    "        zero_points.append(zero_point)\n",
    "\n",
    "    quantized_tensor = torch.concat(quantized_list, dim=0)\n",
    "    quantized_tensor = quantized_tensor.transpose(0, channel_dim) if channel_dim != 0 else quantized_tensor\n",
    "\n",
    "    scales = torch.tensor(scales)\n",
    "    zero_points = torch.tensor(zero_points)\n",
    "\n",
    "    return quantized_tensor, scales, zero_points\n",
    "\n",
    "def dequantize_per_channel(quantized_tensor: torch.tensor, scales: torch.tensor, zero_points: torch.tensor, channel_dim: int):\n",
    "    quantized_tensor = quantized_tensor.transpose(0, channel_dim) if channel_dim != 0 else quantized_tensor\n",
    "    tensors = []\n",
    "\n",
    "    for c in range(quantized_tensor.shape[0]):\n",
    "        quantized_data = quantized_tensor[c,:]\n",
    "        data = (quantized_data - zero_points[c]).float() * scales[c]\n",
    "\n",
    "        tensors.append(data)\n",
    "\n",
    "    tensors = torch.concat(tensors, dim=0)\n",
    "    tensors = tensors.transpose(0, channel_dim) if channel_dim != 0 else tensors\n",
    "\n",
    "    return tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f251cddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantizedLinearLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=True)\n",
    "\n",
    "        self.register_buffer('weight_quantized', torch.zeros(out_features, in_features, dtype=torch.int8))\n",
    "        self.register_buffer('weight_scale', torch.zeros(out_features))\n",
    "        self.register_buffer('weight_zero_point', torch.zeros(out_features))\n",
    "\n",
    "        self.register_buffer('activation_scale', torch.tensor(1.0))\n",
    "        self.register_buffer('activation_zero_point', torch.tensor(0.0))\n",
    "\n",
    "        self.quantized = False\n",
    "\n",
    "    def quantize_weights(self):\n",
    "        weight = self.linear.weight.data\n",
    "        quantized_weight, scale, zero_point = per_channel_quantization(weight, channel_dim=0)\n",
    "\n",
    "        self.weight_quantized = quantized_weight\n",
    "        self.weight_scale = scale\n",
    "        self.weight_zero_point = zero_point\n",
    "\n",
    "        self.quantized = True\n",
    "\n",
    "    def set_activation_scale(self, scale, zero_point):\n",
    "        self.activation_scale = scale\n",
    "        self.activation_zero_point = zero_point\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.quantized:\n",
    "            return self.linear(x)\n",
    "        \n",
    "        quantized_x = torch.clamp(\n",
    "            x / self.activation_scale + self.activation_zero_point, \n",
    "            -127, 127\n",
    "        ) # assume 8 bit quantization\n",
    "\n",
    "        output = torch._ops.quantized.linear(\n",
    "            quantized_x,\n",
    "            self.weight_quantized,\n",
    "            self.weight_scale,\n",
    "            self.weight_zero_point,\n",
    "            self.activation_scale,\n",
    "            self.activation_zero_point\n",
    "        )\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35115d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantizedModel(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = QuantizedLinearLayer(in_features, hidden_features)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = QuantizedLinearLayer(hidden_features, hidden_features)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = QuantizedLinearLayer(hidden_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.fc1(x))\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def quantize_weights(self):\n",
    "        self.fc1.quantize_weights()\n",
    "        self.fc2.quantize_weights()\n",
    "        self.fc3.quantize_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30121243",
   "metadata": {},
   "source": [
    "#### Min-Max Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7a90c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_activations(model, layer_name, calibration_loader):\n",
    "    activations = []\n",
    "\n",
    "    def hook_fn(model, input, output):\n",
    "        activations.append(output.detach().cpu())\n",
    "        \n",
    "    module = dict(model.named_modules())[layer_name]\n",
    "    handle = module.register_forward_hook(hook_fn)\n",
    "        \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in calibration_loader:\n",
    "            _ = model(data)\n",
    "\n",
    "    handle.remove()\n",
    "\n",
    "    activations = torch.cat(activations, dim=0)\n",
    "    max_val = activations.max()\n",
    "    min_val = activations.min()\n",
    "\n",
    "    scale = max(abs(min_val), abs(max_val)) / 255\n",
    "\n",
    "    return scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9b831a",
   "metadata": {},
   "source": [
    "#### Percentile Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77c4f50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile_calibration(activations, percentile=99.99):\n",
    "    acts = activations.flatten()\n",
    "\n",
    "    alpha = (100 - percentile) / 2\n",
    "    lower_quantile = torch.quantile(acts, alpha)\n",
    "    upper_quantile = torch.quantile(acts, 1. - alpha)\n",
    "\n",
    "    acts_clipped = torch.clamp(acts, lower_quantile, upper_quantile)\n",
    "\n",
    "    scale = max(abs(lower_quantile), abs(upper_quantile)) / 127\n",
    "    \n",
    "    return scale, lower_quantile, upper_quantile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb36b6fd",
   "metadata": {},
   "source": [
    "#### MSE Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a0810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_calibration(activations, num_candidates=100):\n",
    "    max_val = activations.max()\n",
    "\n",
    "    candidates = torch.linspace(max_val * 0.5, max_val, steps=num_candidates)\n",
    "    best_candidate = None\n",
    "    best_scale = None\n",
    "    mse = float('inf')\n",
    "\n",
    "    for candidate in candidates:\n",
    "        scale = candidate / 127\n",
    "\n",
    "        quantized = torch.clamp(\n",
    "            activations / scale, \n",
    "            -127, 127\n",
    "        ).to(torch.int8)\n",
    "\n",
    "        dequantized = quantized.float() * scale\n",
    "\n",
    "        loss = torch.square(activations - dequantized).sum().item()\n",
    "\n",
    "        if loss < mse:\n",
    "            mse = loss\n",
    "            best_scale = scale\n",
    "            best_candidate = candidate\n",
    "\n",
    "    return best_scale, best_candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e4e891",
   "metadata": {},
   "source": [
    "### Quantization Aware Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b48a3137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42847956",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeQuantize(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, scale, zero_point, q_min, q_max):\n",
    "        quantized = torch.clamp(\n",
    "            input / scale + zero_point,\n",
    "            q_min, q_max\n",
    "        ).to(torch.int8)\n",
    "\n",
    "        dequantized = (quantized - zero_point).float() * scale\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output, None, None, None, None\n",
    "    \n",
    "fakequantize = FakeQuantize.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c471c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxObserver(nn.Module):\n",
    "    def __init__(self, n_bits=8):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_bits = n_bits\n",
    "        self.q_max = 2 ** (n_bits - 1) - 1\n",
    "        self.q_min = - self.q_max\n",
    "\n",
    "        self.register_buffer('min_val', torch.tensor(float('inf')))\n",
    "        self.register_buffer('max_val', torch.tensor(float('-inf')))\n",
    "\n",
    "        self.register_buffer('scale', torch.tensor(1.0))\n",
    "        self.register_buffer('zero_poinr', torch.tensor(0.0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            current_min = x.min()\n",
    "            current_max = x.max()\n",
    "\n",
    "            self.min_val = min(self.min_val, current_min)\n",
    "            self.max_val = max(self.max_val, current_max)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def calculate_params(self):\n",
    "        self.scale = (self.max_val - self.min_val) / (self.q_max - self.q_min)\n",
    "        if self.scale == 0.0:\n",
    "            self.scale = 1.0\n",
    "\n",
    "        self.zero_point = self.q_min - self.min_val / self.scale\n",
    "\n",
    "        return self.scale, self.zero_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db0d8a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovingAverageMinMaxObserver(MinMaxObserver):\n",
    "    def __init__(self, n_bits=8, averaging_constant=0.01):\n",
    "        super().__init__(n_bits)\n",
    "\n",
    "        self.averaging_constant = averaging_constant\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            current_min = x.min()\n",
    "            current_max = x.max()\n",
    "\n",
    "            if self.min_val == float('inf'):\n",
    "                self.min_val = current_min\n",
    "            else:\n",
    "                self.min_val = self.averaging_constant * current_min + (1. - self.averaging_constant) * self.min_val\n",
    "            \n",
    "            if self.max_val == float('-inf'):\n",
    "                self.max_val = current_max\n",
    "            else:\n",
    "                self.max_val = self.averaging_constant * current_max + (1. - self.averaging_constant) * self.max_val\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff34c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QATLinearLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=True)\n",
    "\n",
    "        self.activation_observer = MovingAverageMinMaxObserver()\n",
    "        self.register_buffer(\"activation_scale\", None)\n",
    "        self.register_buffer(\"activation_zero_point\", None)\n",
    "\n",
    "        self.qat_mode = False\n",
    "\n",
    "    def enable_observer(self):\n",
    "        self.activation_observer.train()\n",
    "\n",
    "    def disble_observer(self):\n",
    "        self.activation_observer.eval()\n",
    "\n",
    "    def calculate_params(self):\n",
    "        scale, zero_point = self.activation_observer.calculate_params()\n",
    "        self.activation_scale = scale\n",
    "        self.activation_zero_point = zero_point\n",
    "\n",
    "    def enable_qat(self):\n",
    "        self.qat_mode = True\n",
    "        self.disble_observer()\n",
    "        self.calculate_params()\n",
    "\n",
    "    def forward(self):\n",
    "        x = self.activation_observer(x)\n",
    "\n",
    "        if not self.qat_mode:\n",
    "            return self.linear(x)\n",
    "        \n",
    "        x_fq = fakequantize(\n",
    "            x, self.activation_scale, self.activation_zero_point, \n",
    "            self.activation_observer.min_val,\n",
    "            self.activation_observer.max_val\n",
    "        )\n",
    "\n",
    "        quantized_weights = per_channel_quantization(self.linear.weight.data)\n",
    "\n",
    "        return nn.functional.linear(x_fq, quantized_weights, self.linear.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38429887",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QATModel(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = QATLinearLayer(in_features, hidden_features)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = QATLinearLayer(hidden_features, hidden_features)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = QATLinearLayer(hidden_features, out_features)\n",
    "\n",
    "    def enable_observer(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, QATLinearLayer):\n",
    "                module.enable_observer()\n",
    "\n",
    "    def disable_observer(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, QATLinearLayer):\n",
    "                module.disble_observer()\n",
    "\n",
    "    def calculate_params(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, QATLinearLayer):\n",
    "                module.calculate_params()\n",
    "\n",
    "    def enable_qat(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, QATLinearLayer):\n",
    "                module.enable_qat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
