{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbe714da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b07aec4",
   "metadata": {},
   "source": [
    "#### Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd8f9565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_pred, y_true):\n",
    "    return torch.mean(torch.square(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb26ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_errors(y_pred, y_true):\n",
    "    return torch.mean(torch.abs(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37afc638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(y_pred, y_true, eps=1e-15):\n",
    "    y_pred = torch.clamp(y_pred, eps, 1. - eps)\n",
    "    return - torch.mean(y_true * torch.log(y_pred) + (1 - y_true) * torch.log(1 - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1575fdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_cross_entropy(y_true, y_pred):\n",
    "    return - torch.mean(y_true * torch.log(y_pred), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3094886",
   "metadata": {},
   "source": [
    "#### Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01ed12c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + torch.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f3e890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return (torch.exp(-x) - torch.exp(x)) / (torch.exp(-x) + torch.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9ef46d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x) / torch.sum(torch.exp(x), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0291abf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return torch.max(x, torch.tensor(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "376bd6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(x, alpha):\n",
    "    return torch.max(x, alpha * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a4cbe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swish(x):\n",
    "    return x * sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "570f5af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponent_linear_unit(x, alpha=0.1):\n",
    "    if x >= torch.tensor(0):\n",
    "        return x\n",
    "    else:\n",
    "        return alpha * (torch.exp(x) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2921eb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_exponent_linear_unit(x, alpha=0.1, lambda_p=1.2):\n",
    "    if x >= torch.tensor(0):\n",
    "        return lambda_p * x\n",
    "    else:\n",
    "        return lambda_p * alpha * (torch.exp(x) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07783064",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40c9c144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradients(y_pred, y_true, x):\n",
    "    dw = - 2 * torch.mean(y_pred - y_true) * x\n",
    "    db = - 2 * torch.mean(y_pred - y_true)\n",
    "\n",
    "    return dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a35ad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(y_true, x, w, b, learning_rate, iterations):\n",
    "    for i in range(iterations):\n",
    "        y_pred = w * x + b\n",
    "        loss = mean_squared_error(y_pred, y_true)\n",
    "\n",
    "        dw, db = compute_gradients(y_pred, y_true, x)\n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db\n",
    "\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32746677",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "524b912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, in_featurs, n_labels):\n",
    "        self.W = torch.randn(in_featurs, n_labels)\n",
    "        self.b = torch.zeros(n_labels)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + torch.exp(-x))\n",
    "    \n",
    "    def cross_entropy(self, y_pred, y_true):\n",
    "        return torch.mean(y_true * torch.log(y_pred) + (1 - y_true) * torch.log(1 - y_pred))\n",
    "    \n",
    "    def compute_gradients(self, y_pred, y_true, x):\n",
    "        df = y_pred - y_true\n",
    "\n",
    "        dw = torch.mean(x * df)\n",
    "        db = torch.mean(df)\n",
    "\n",
    "        return dw, db\n",
    "    \n",
    "    def backward(self, learning_rate, dw, db):\n",
    "        self.W = self.W - learning_rate * dw\n",
    "        self.b = self.b - learning_rate * db\n",
    "\n",
    "    def forward(self, X, y, learning_rate, iterations):\n",
    "        for i in range(iterations):\n",
    "            y_pred = self.W * X + self.b\n",
    "            loss = self.cross_entropy(y_pred, y)\n",
    "            dw, db = self.compute_gradients(y_pred, y, X)\n",
    "            self.backward(learning_rate, dw, db)\n",
    "\n",
    "        return self.W, self.b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd6452c",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2954199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, in_features, out_features):\n",
    "        self.W = torch.randn(in_features, out_features)\n",
    "        self.b = torch.randn(out_features)\n",
    "\n",
    "    def mean_squared_error(self, y_pred, y_true):\n",
    "        return torch.mean(torch.square(y_pred - y_true))\n",
    "    \n",
    "    def compute_gradients(self, y_pred, y_true, x):\n",
    "        df = (y_pred - y_true)\n",
    "\n",
    "        dw = - 2 * torch.mean(df) * x\n",
    "        db = - 2 * torch.mean(df)\n",
    "\n",
    "        return dw, db\n",
    "    \n",
    "    def backward(self, dw, db, learning_rate):\n",
    "        self.W = self.W - learning_rate * dw\n",
    "        self.b = self.b - learning_rate * db\n",
    "\n",
    "    def forward(self, X, y, learning_rate, iterations):\n",
    "        for i in range(iterations):\n",
    "            y_pred = self.W * X + self.b\n",
    "            loss = self.mean_squared_error(y_pred, y)\n",
    "            dw, db = self.compute_gradients(y_pred, y, X)\n",
    "            self.backward(dw, db, learning_rate)\n",
    "\n",
    "        return self.W, self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6b38ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
